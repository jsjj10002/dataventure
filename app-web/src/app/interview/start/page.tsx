'use client';

import { useState, useEffect, useRef, Suspense } from 'react';
import { useRouter, useSearchParams } from 'next/navigation';
import { Mic, MicOff, Volume2, VolumeX, Clock, X, MessageSquare, Subtitles, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { useAuthStore } from '@/stores/authStore';
import { interviewAPI } from '@/lib/api';
import toast from 'react-hot-toast';
import dynamic from 'next/dynamic';
import { getSocket, connectSocket, onSocketEvent, offSocketEvent, emitSocketEvent, disconnectSocket } from '@/lib/socket-client';

// 3D ì•„ë°”íƒ€ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œ (SSR ë¹„í™œì„±í™”)
// GLTF ê¸°ë°˜ Ready Player Me ì•„ë°”íƒ€ ì‚¬ìš©
const AIAvatar3D = dynamic(() => import('@/components/interview/AIAvatarGLTF'), {
  ssr: false,
  loading: () => (
    <div className="flex items-center justify-center h-full">
      <Loader2 className="h-8 w-8 animate-spin text-primary" />
    </div>
  ),
});

interface Message {
  role: 'AI' | 'USER';
  content: string;
  timestamp: Date;
}

function InterviewContent() {
  const router = useRouter();
  const searchParams = useSearchParams();
  const interviewId = searchParams.get('id');
  const voiceModeParam = searchParams.get('voiceMode'); // URL íŒŒë¼ë¯¸í„°ì—ì„œ ëª¨ë“œ ì½ê¸°
  
  const { user, isAuthenticated } = useAuthStore();
  
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputMessage, setInputMessage] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [isSending, setIsSending] = useState(false);
  const [timeLeft, setTimeLeft] = useState(15 * 60);
  const [isInterviewActive, setIsInterviewActive] = useState(true);
  const [interviewMode, setInterviewMode] = useState<'PRACTICE' | 'REAL'>('PRACTICE');
  
  // ì›¹ìº  & ìŒì„±
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [isAISpeaking, setIsAISpeaking] = useState(false);
  
  // UI ëª¨ë“œ - URL íŒŒë¼ë¯¸í„°ì—ì„œ ì´ˆê¸°í™” (ê¸°ë³¸ê°’: true)
  const [isVoiceMode, setIsVoiceMode] = useState(voiceModeParam === 'true' || voiceModeParam === null); // ìŒì„±/ì±„íŒ… ëª¨ë“œ
  const [showSubtitles, setShowSubtitles] = useState(false); // ìë§‰ í‘œì‹œ
  const [currentSubtitle, setCurrentSubtitle] = useState('');
  
  const [mousePosition, setMousePosition] = useState({ x: 0, y: 0 });
  
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null); // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¶”ì 

  // ì¸ì¦ í™•ì¸
  useEffect(() => {
    if (!isAuthenticated) {
      toast.error('ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.');
      router.push('/auth/login');
      return;
    }
    
    if (!interviewId) {
      toast.error('ì¸í„°ë·° IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      router.push('/interview/setup');
      return;
    }
    
    loadInterview();
    
    return () => {
      if (timerRef.current) clearInterval(timerRef.current);
      stopCamera();
      disconnectSocket();
    };
  }, []);

  // ë§ˆìš°ìŠ¤ ì›€ì§ì„ ì¶”ì 
  useEffect(() => {
    const handleMouseMove = (e: MouseEvent) => {
      setMousePosition({ x: e.clientX, y: e.clientY });
    };
    window.addEventListener('mousemove', handleMouseMove);
    return () => window.removeEventListener('mousemove', handleMouseMove);
  }, []);

  const loadInterview = async () => {
    if (!interviewId) return;
    
    try {
      const response = await interviewAPI.get(interviewId);
      const interview = response.data;
      
      setInterviewMode(interview.mode);
      setTimeLeft(interview.timeLimitSeconds);
      
      // ì‹¤ì „ ëª¨ë“œëŠ” ìŒì„± ëª¨ë“œ ê³ ì •
      if (interview.mode === 'ACTUAL') {
        setIsVoiceMode(true);
      }
      
      // AI ì¸ì‚¬ ë©”ì‹œì§€
      const greeting = 'ì•ˆë…•í•˜ì„¸ìš”! AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ë“¯ì´ ë‹µë³€í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?';
      setMessages([{
        role: 'AI',
        content: greeting,
        timestamp: new Date(),
      }]);
      
      // ìë§‰ í‘œì‹œ
      if (showSubtitles) {
        setCurrentSubtitle(greeting);
      }
      
      // AI ì¸ì‚¬ë§ ìŒì„± ì¬ìƒ (ëª¨ë“  ëª¨ë“œì—ì„œ ì¬ìƒ)
      await speakText(greeting);
      
    // íƒ€ì´ë¨¸ ì‹œì‘
    startTimer();
    
    // ì›¹ìº  ìë™ ì‹œì‘ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ì¸í„°ë·° ì§„í–‰)
    setTimeout(() => {
      startCamera().catch((err) => {
        console.warn('ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨, ê³„ì† ì§„í–‰:', err);
      });
    }, 500);
    } catch (error: any) {
      console.error('ì¸í„°ë·° ë¡œë“œ ì‹¤íŒ¨:', error);
      toast.error('ì¸í„°ë·°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      router.push('/interview/setup');
    }
  };

  // íƒ€ì´ë¨¸ ì‹œì‘
  const startTimer = () => {
    timerRef.current = setInterval(() => {
      setTimeLeft((prev) => {
        if (prev <= 1) {
          handleEndInterview();
          return 0;
        }
        return prev - 1;
      });
    }, 1000);
  };

  // ë©”ì‹œì§€ ì „ì†¡
  const handleSendMessage = async () => {
    if (!inputMessage.trim() || isSending || !interviewId) return;
    
    const userMessage = inputMessage.trim();
    setInputMessage('');
    setIsSending(true);
    
    // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    setMessages((prev) => [...prev, {
      role: 'USER',
      content: userMessage,
      timestamp: new Date(),
    }]);
    
    try {
      // Socket.IOë¥¼ í†µí•´ ë©”ì‹œì§€ ì „ì†¡
      const socket = getSocket();
      if (!socket.connected) {
        connectSocket();
        await new Promise((resolve) => {
          socket.once('connect', resolve);
        });
      }
      
      // ê¸°ì¡´ ë¦¬ìŠ¤ë„ˆ ì œê±° (ì¤‘ë³µ ë°©ì§€)
      offSocketEvent('interview:question');
      
      // AI ì‘ë‹µ ìˆ˜ì‹  ë¦¬ìŠ¤ë„ˆ ë“±ë¡
      const questionListener = async (data: any) => {
        const aiMessage: Message = {
          role: 'AI',
          content: data.content,
          timestamp: new Date(data.createdAt),
        };
        setMessages((prev) => [...prev, aiMessage]);
        
        // ìë§‰ í‘œì‹œ
        if (showSubtitles) {
          setCurrentSubtitle(data.content);
        }
        
        // AI ì‘ë‹µì„ í•­ìƒ ìŒì„±ìœ¼ë¡œ ì¬ìƒ (ì±„íŒ…/ìŒì„± ëª¨ë“œ ëª¨ë‘)
        await speakText(data.content);
        
        setIsSending(false);
      };
      
      onSocketEvent('interview:question', questionListener);
      
      // ë©”ì‹œì§€ ì „ì†¡
      emitSocketEvent('interview:message', {
        interviewId,
        content: userMessage,
        contentType: 'TEXT',
      });
    } catch (error: any) {
      console.error('ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨:', error);
      toast.error('ë©”ì‹œì§€ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      setIsSending(false);
    }
  };

  // ì›¹ìº  ì‹œì‘ (ì„ íƒì‚¬í•­ - ê¸°ê¸° ì—†ì–´ë„ ì§„í–‰ ê°€ëŠ¥)
  const startCamera = async () => {
    try {
      // ë¯¸ë””ì–´ ê¸°ê¸° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.warn('ë¯¸ë””ì–´ ê¸°ê¸°ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.');
        toast('ì¹´ë©”ë¼ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.', { icon: 'â„¹ï¸' });
        return;
      }

      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true,
      });
      
      setStream(mediaStream);
      setIsCameraOn(true);
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
      }
      
      toast.success('ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
    } catch (error: any) {
      console.error('ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      
      // ê¸°ê¸°ê°€ ì—†ê±°ë‚˜ ê¶Œí•œ ê±°ë¶€ ì‹œì—ë„ ì§„í–‰ ê°€ëŠ¥
      if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        toast('ì¹´ë©”ë¼/ë§ˆì´í¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.', { icon: 'â„¹ï¸' });
      } else if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        toast('ì¹´ë©”ë¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.', { icon: 'â„¹ï¸' });
      } else {
        toast('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.', { icon: 'â„¹ï¸' });
      }
      
      // ì—ëŸ¬ ë°œìƒí•´ë„ ì¸í„°ë·°ëŠ” ê³„ì† ì§„í–‰
      setIsCameraOn(false);
      setStream(null);
    }
  };

  // ì›¹ìº  ì¤‘ì§€
  const stopCamera = () => {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
      setIsCameraOn(false);
      
      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }
    }
  };

  // ìŒì„± ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    // ìŠ¤íŠ¸ë¦¼ì´ ì—†ìœ¼ë©´ ë§ˆì´í¬ë§Œ ìš”ì²­
    if (!stream) {
      try {
        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        setStream(audioStream);
      } catch (error: any) {
        console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
        
        if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
          toast.error('ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
        } else if (error.name === 'NotAllowedError') {
          toast.error('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
        } else {
          toast.error('ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
        }
        return;
      }
    }
    
    try {
      const recorder = new MediaRecorder(stream);
      const chunks: Blob[] = [];
      
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunks.push(e.data);
        }
      };
      
      recorder.onstop = async () => {
        const audioBlob = new Blob(chunks, { type: 'audio/webm' });
        await sendAudioToSTT(audioBlob);
      };
      
      recorder.start();
      setMediaRecorder(recorder);
      setIsRecording(true);
      setAudioChunks(chunks);
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      toast.error('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  // ìŒì„± ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      setIsRecording(false);
    }
  };

  // STT: ìŒì„± â†’ í…ìŠ¤íŠ¸
  const sendAudioToSTT = async (audioBlob: Blob) => {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'recording.webm');
    
    try {
      const response = await fetch('http://localhost:8000/api/v1/ai/stt/transcribe', {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) throw new Error('STT ì‹¤íŒ¨');
      
      const data = await response.json();
      setInputMessage(data.text);
      toast.success('ìŒì„±ì´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!');
    } catch (error) {
      console.error('STT ì‹¤íŒ¨:', error);
      toast.error('ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // TTS: í…ìŠ¤íŠ¸ â†’ ìŒì„±
  const speakText = async (text: string) => {
    if (!text) return;
    
    // ì´ì „ ì˜¤ë””ì˜¤ê°€ ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ë‹¨ (ì¤‘ë³µ ë°©ì§€)
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current = null;
    }
    
    setIsAISpeaking(true);
    
    // ìë§‰ í‘œì‹œ
    if (showSubtitles) {
      setCurrentSubtitle(text);
    }
    
    try {
      const response = await fetch('http://localhost:8000/api/v1/ai/tts/speak-korean', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text, voice: 'nova', model: 'tts-1', speed: 1.0 }), // nova: ë” ìì—°ìŠ¤ëŸ¬ìš´ ëª©ì†Œë¦¬
      });
      
      if (!response.ok) throw new Error('TTS ì‹¤íŒ¨');
      
      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio; // í˜„ì¬ ì˜¤ë””ì˜¤ ì¶”ì 
      
      audio.onended = () => {
        setIsAISpeaking(false);
        currentAudioRef.current = null;
        // ìë§‰ ìœ ì§€ (3ì´ˆ í›„ ì§€ìš°ê¸°)
        setTimeout(() => {
          setCurrentSubtitle('');
        }, 3000);
        URL.revokeObjectURL(audioUrl);
      };
      
      audio.onerror = () => {
        setIsAISpeaking(false);
        currentAudioRef.current = null;
        setCurrentSubtitle('');
      };
      
      await audio.play();
    } catch (error) {
      console.error('TTS ì‹¤íŒ¨:', error);
      setIsAISpeaking(false);
      currentAudioRef.current = null;
      setCurrentSubtitle('');
    }
  };

  // ì¸í„°ë·° ì¢…ë£Œ
  const handleEndInterview = async () => {
    if (!interviewId) return;
    
    setIsInterviewActive(false);
    
    try {
      await interviewAPI.complete(interviewId);
      toast.success('ì¸í„°ë·°ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
      router.push(`/evaluation/${interviewId}`);
    } catch (error: any) {
      console.error('ì¸í„°ë·° ì¢…ë£Œ ì‹¤íŒ¨:', error);
      toast.error('ì¸í„°ë·° ì¢…ë£Œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì‹œê°„ í¬ë§·
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="fixed inset-0 overflow-hidden">
      {/* ë°°ê²½ ê·¸ë¼ë°ì´ì…˜ (ì¤‘ì•™ì´ ë” ì–´ë‘¡ê²Œ) */}
      <div className="absolute inset-0 bg-gradient-radial from-gray-900 via-gray-950 to-black" />
      
      {/* ì›¹ìº  (ì˜¤ë¥¸ìª½ ìƒë‹¨ ê³ ì •) */}
      {isCameraOn && (
        <div className="absolute top-6 right-6 z-30">
          <div className="relative rounded-2xl overflow-hidden border-2 border-white/20 shadow-2xl backdrop-blur-sm">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-64 h-48 object-cover bg-gray-900"
            />
          </div>
        </div>
      )}
      
      {/* í—¤ë” */}
      <div className="absolute top-0 left-0 right-0 z-50 flex items-center justify-between px-8 py-3 bg-gradient-to-b from-black/40 to-transparent backdrop-blur-sm pointer-events-none">
        {/* ë²„íŠ¼ë“¤ë§Œ pointer-events-auto ì ìš© */}
        {/* ì¢Œì¸¡: íƒ€ì´ë¨¸ + ëª¨ë“œ */}
        <div className="flex items-center gap-6 pointer-events-auto">
          {/* íƒ€ì´ë¨¸ */}
          <div className="flex items-center gap-3 px-5 py-3 rounded-xl bg-black/40 backdrop-blur-md border border-white/20 shadow-lg">
            <Clock className="h-6 w-6 text-blue-400 animate-pulse" />
            <div className="flex flex-col">
              <span className="text-xs text-white/60 uppercase tracking-wider">ë‚¨ì€ ì‹œê°„</span>
              <span className="text-3xl font-mono font-bold text-white tracking-wider">
                {formatTime(timeLeft)}
              </span>
            </div>
          </div>
          
          {/* êµ¬ë¶„ì„  */}
          <div className="h-10 w-px bg-white/20" />
          
          {/* ëª¨ë“œ í‘œì‹œ */}
          <span className="text-sm text-white/80 font-medium px-4 py-2 rounded-lg bg-white/10 backdrop-blur-sm">
            {interviewMode === 'PRACTICE' ? 'ğŸ¯ ì—°ìŠµ ëª¨ë“œ' : 'ğŸ”¥ ì‹¤ì „ ëª¨ë“œ'}
          </span>
        </div>
        
        {/* ìš°ì¸¡: ìë§‰ + ì¢…ë£Œ ë²„íŠ¼ */}
        <div className="flex items-center gap-3 pointer-events-auto">
          {/* ìë§‰ í† ê¸€ */}
          <Button
            variant="ghost"
            size="sm"
            onClick={() => setShowSubtitles(!showSubtitles)}
            className="text-white hover:bg-white/20 backdrop-blur-sm"
          >
            <Subtitles className="h-4 w-4 mr-2" />
            {showSubtitles ? 'ìë§‰ ë„ê¸°' : 'ìë§‰ ì¼œê¸°'}
          </Button>
          
          {/* ì¢…ë£Œ ë²„íŠ¼ */}
          <Button
            variant="destructive"
            size="sm"
            onClick={handleEndInterview}
            disabled={!isInterviewActive}
            className="shadow-lg"
          >
            <X className="h-4 w-4 mr-2" />
            ì¸í„°ë·° ì¢…ë£Œ
          </Button>
        </div>
      </div>
      
      {/* ì¤‘ì•™ 3D ìºë¦­í„° */}
      <div className="absolute inset-0 z-10 flex items-center justify-center pointer-events-none">
        <AIAvatar3D 
          isSpeaking={isAISpeaking}
          emotion={isAISpeaking ? 'happy' : 'neutral'}
          className="w-full h-full"
          mousePosition={mousePosition}
        />
      </div>
      
      {/* ìë§‰ (í•˜ë‹¨ ì¤‘ì•™) */}
      {showSubtitles && currentSubtitle && (
        <div className="absolute bottom-32 left-1/2 transform -translate-x-1/2 z-20 max-w-4xl px-8">
          <div className="bg-black/90 text-white text-center px-8 py-4 rounded-lg text-lg font-medium shadow-2xl">
            {currentSubtitle}
          </div>
        </div>
      )}
      
      {/* í•˜ë‹¨ ì»¨íŠ¸ë¡¤ ì˜ì—­ */}
      <div className="absolute bottom-0 left-0 right-0 z-10 pb-8 pt-16 bg-gradient-to-t from-black/70 via-black/30 to-transparent">
        <div className="max-w-3xl mx-auto px-4">
          {isVoiceMode ? (
            /* ìŒì„± ëª¨ë“œ: ì„¸ë ¨ëœ ë§ˆì´í¬ ë²„íŠ¼ */
            <div className="flex flex-col items-center justify-center gap-6">
              <div className="relative">
                {/* í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ (ë…¹ìŒ ì¤‘) */}
                {isRecording && (
                  <>
                    <div className="absolute inset-0 rounded-full bg-red-500 opacity-20 animate-ping" />
                    <div className="absolute inset-0 rounded-full bg-red-500 opacity-30 animate-pulse" />
                  </>
                )}
                
                {/* ë§ˆì´í¬ ë²„íŠ¼ */}
                <Button
                  size="lg"
                  onClick={isRecording ? stopRecording : startRecording}
                  disabled={!isInterviewActive || isSending}
                  className={`relative h-32 w-32 rounded-full shadow-2xl transition-all duration-300 ${
                    isRecording
                      ? 'bg-gradient-to-br from-red-500 to-red-700 hover:from-red-600 hover:to-red-800 scale-110'
                      : 'bg-gradient-to-br from-primary-500 to-primary-700 hover:from-primary-600 hover:to-primary-800 hover:scale-110'
                  }`}
                >
                  {isRecording ? (
                    <MicOff className="h-16 w-16" />
                  ) : (
                    <Mic className="h-16 w-16" />
                  )}
                </Button>
              </div>
              
              {/* ìƒíƒœ í…ìŠ¤íŠ¸ */}
              <div className="text-center">
                {isRecording ? (
                  <div className="flex items-center gap-2">
                    <div className="h-3 w-3 rounded-full bg-red-500 animate-pulse" />
                    <p className="text-white font-medium text-lg">ë…¹ìŒ ì¤‘...</p>
                  </div>
                ) : (
                  <p className="text-white/80 font-medium">
                    ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€í•˜ì„¸ìš”
                  </p>
                )}
              </div>
            </div>
          ) : (
            /* ì±„íŒ… ëª¨ë“œ: Glass UI ì…ë ¥ë°” */
            <div className="relative">
              <div className="backdrop-blur-xl bg-white/10 rounded-3xl border border-white/20 shadow-2xl p-2">
                <div className="flex items-center gap-2">
                  <input
                    type="text"
                    value={inputMessage}
                    onChange={(e) => setInputMessage(e.target.value)}
                    onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                    disabled={!isInterviewActive || isSending}
                    className="flex-1 bg-transparent text-white placeholder-white/50 px-6 py-4 outline-none text-lg"
                  />
                  <Button
                    onClick={handleSendMessage}
                    disabled={!inputMessage.trim() || isSending || !isInterviewActive}
                    size="lg"
                    className="rounded-2xl px-8 shadow-lg"
                  >
                    <MessageSquare className="h-5 w-5 mr-2" />
                    ì „ì†¡
                  </Button>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
}

export default function InterviewStartPage() {
  return (
    <Suspense fallback={
      <div className="fixed inset-0 bg-gray-900 flex items-center justify-center">
        <div className="text-white text-xl">ë¡œë”© ì¤‘...</div>
      </div>
    }>
      <InterviewContent />
    </Suspense>
  );
}
